<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Portfolio</title>

<script src="site_libs/header-attrs-2.19/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HOME</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Portfolio.html">Portfolio</a>
</li>
<li>
  <a href="Contact.html">Contact</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Portfolio</h1>

</div>


<hr />
<button class="collapsible">
Projects
</button>
<div class="content">
<p>
<ul>
<button class="collapsible">
<p2>USING TEXT DATA TO STUDY THE IMPACT OF NEWS SOURCE ON DISCOURSE
</p2><mark style="color:#B8C0AF;font-size:11px;background:#f7f7f7">[NLP;
ETL; LLM; TRANSFORMER MODELS; BIG DATA]</mark>
</button>
<div class="content">
<p>
<ul>
<h2 style="color:Black;font-size:18px;">
Main Contributions
</h2>
<ul>
<li>
Extracted billions of tweets and replies from Twitter API using SQL,
Python, and web scraping techniques
</li>
<li>
Transformed, cleansed, and normalized with Python, Pandas, and regular
expressions
</li>
<li>
Optimized data collection and transformation tasks using parallel
processing, indexing, and caching
</li>
<li>
Automated the data collection process to streamline data management
processes for multiple collaborators
</li>
<li>
Ensured data reliability and pipeline stability by developing logging
and alerting mechanism to handle errors
</li>
</ul>
<hr />
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
The purpose of this project was to explore the ways discourse varies
dependent upon the news outlet reporting. To do so, we collected Tweets
shared by news organizations and their replies dating back to 2017. The
data collected yielded (soon to be published) insights into variations
such as sentiment and similarity. It also invited the use of techniques
such as topic modeling and interrupted times series analyses surrounding
the events of January 6, 2022. We sought to understand patterns related
to the emotional charge and sentiment of text and how this varied across
different news outlets and topics.
</p>
<hr />
<h3 style="color:Black;font-size:18px;">
Methods
</h3>
<p style="padding-left: 5px;">
My major contribution to this project was the development of a reliable
ETL pipeline that enabled non-methods researchers to easily load and
explore the data. To do so, I first created a a Python script to parse
and normalize the data. This involved pagination to fetch large volumes
of data and error handling to handle API rate limits and other potential
issues. The data retrieved included tweet-level information, media-level
information, and context annotations. Logging was implemented to track
the progress of the script and help diagnose issues that may arise
during the data collection process. The main function was to allow
multiple users to divide the work and run the script in parallel without
repetition.
</p>
<p style="padding-left: 5px;">
I then developed a program that allowed users to automatically extract
useful metrics from the data, store the cleansed data in a SQL database
and prevent duplicate data processing. This program included
preprocessing the text data with methods such as removing unnecessary
characters, renaming columns, extracting links, tokenization,
lemmatization and calculating various text-based metrics like average
word length and total word count. Other features include an unsupervised
learning algorithm for obtaining vector representations of words and
computing the subjectivity, polarity, and sentiment analysis scores for
each tweet
</p>
</ul>
</p>
</div>
<button class="collapsible">
<p2>IDENTIFYING WHAT CONSTITUTES A POLITICAL ADVERTISEMENT </p2>
<mark style="color:#B8C0AF;font-size:11px;background:#f7f7f7"> [DATA
ANALYSIS &amp; VISUALIZTION; CONJOINT EXPERIMENT]</mark>
</button>
<div class="content">
<ul>
<h2 style="color:Black;font-size:18px;">
Main Contributions
</h2>
<ul>
<li>
Collaborated with multidisciplinary team, providing insights and
recommendations based on key findings
</li>
<li>
Conducted exploratory data analysis using data visualization tools such
as ggplot2 and plotly
</li>
<li>
Identified experiment-breaking distribution error which necessitated
reissuance
</li>
<li>
Implemented data transformation techniques including variable recoding,
data aggregation, and normalization
</li>
<li>
Presented research findings in poster (displayed below) with
visualizations, summary and Q &amp; A at the Annual Conference for
Political Methodology
</li>
</ul>
<ul>
<div class="image-container" id="imageContainer">
<img src='images/poster.jpg' class="image-zoom" id="imageZoom">
<div>
</ul>
<hr />
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
In this project, we investigated social media users’ perceptions of
digital political ads. We measured users’ opinions on how platforms
should design political ad UX and policies with the goal of establishing
a baseline understanding of user opinions’ including the permissibly of
political ads and microtargeting, transparency in funding.
</p>
<p style="padding-left: 5px;">
The primary objective of this research was to understand what factors of
ads (and users themselves) may contribute to their perceptions of how
`political’ given digital ads are. To do this, we conducted a conjoint
experiment asking respondents to compare artificial Facebook ads where
we altered their source, content, and political orientation. This
conjoint design allowed us to isolate the independent effects of each
component on perceptions of the political.
</p>
<p style="padding-left: 5px;">
We also conducted a within-between experiment asking respondents to
evaluate real ads drawn from the Facebook Ad Library (collected by
co-author). In this portion of the project, we randomly assigned
respondents’ to view either a political or non-political advertisement
and asked to rate how political they perceived it to be. Respondents
rated multiple ads (within-subject variation) but the exact composition
of the ads was randomized for each respondent (between-subject
variation)
</p>
<p style="padding-left: 5px;">
Overall, our conjoint analysis strongly supported our original research
hypotheses showing that the source, strength, and orientation of the
message all matter. We found that candidate ads seem to be viewed as
inherently political, in contrast to sources such as politically active
companies and advocacy organizations, where message strength appears to
matter far more in order for an ad to be considered political. This
differs from our finding in the conjoint analysis, where ads from
companies and advocacy organizations were viewed as equally political.
</p>
<hr />
<h3 style="color:Black;font-size:18px;">
Methods
</h3>
<p style="padding-left: 5px;">
<p>I was brought into this project after the research design and
implementation stages of the surveys had taken place and tasked with the
responsibility of maintaining and overseeing the data for a project. I
quickly acquired a working understanding of the mathematical principles
and methodologies behind conjoint experiments, a less-common analytical
approach in my field. Upon examination of the data and methods, I
identified discrepancies in the expected number of profiles,
subsequently informing my collaborators of the error which had
compromised the random assignment. Consequently, the survey distributor
rectified the parameters and redistributed the survey, ensuring the
project’s successful progression.</p>
I implemented analyses in this project in R, using libraries such as
dplyr, magrittr, and tidyverse to analyze political ad data and examine
the impact of ad orientation on political preferences. I developed an R
script to clean and process the data in order to create relevant
variables and handle missingness. I implemented advanced data
manipulation techniques and reshaped the datasets to make them more
manageable for further analysis.
</p>
<p style="padding-left: 5px;">
I then conducted a comprehensive analysis on political advertisement
data, encompassing four novel datasets. Utilizing weighted confidence
intervals and an array of statistical techniques, I visualized the
findings through point-range plots, effectively conveying the political
nature of the ad content. Additionally, I carried out a follow-up study
to further investigate the perceived political content of various
advertisements, expanding the project’s scope and providing a more
in-depth understanding of the relationship between ad content and
political affiliation.
</p>
<p style="padding-left: 5px;">
Across the two experiments, we found no evidence supporting our
hypotheses. While Study 1 showed that corrective comments in the
comments section effectively reduced misperceptions, culturally relevant
corrections were not particularly effective among Latinos. In Study 2,
we did not find evidence to support the hypothesis that culturally
relevant comments are more effective in reducing misperceptions.
Interestingly, the in-group corrections from those who were the target
of misinformation were most effective among all participants in both
experiments, which may suggest that members of out-groups defer to other
ethnic groups when the misinformation does not relate to them.
</p>
</div>
<button class="collapsible">
<p2>MEASURING THE EFFICACY OF IN-GROUP CORRECTIONS</p2>
<mark style="color:#B8C0AF;font-size:11px;background:#f7f7f7">[EXPERIMENTAL
DESIGN; DATA ANALYSIS &amp; VISUALIZATION]</mark>
</button>
<div class="content">
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
This project aimed to investigate the effectiveness of corrective
comments on social media in reducing misinformation, specifically
examining the role of in-group and out-group members in promoting
accurate beliefs. We hypothesized that comments from in-group members
would be more effective in promoting accurate beliefs than comments from
out-group members, particularly when the misinformation relates to the
target’s ethnic group. We also hypothesized that corrective comments
from culturally relevant organizations would be more effective in
reducing misperceptions.
</p>
<ul>
<div class="image-container" id="imageContainer">
<img src='images/misinfo.png' class="image-zoom" id="imageZoom">
<div>
</ul>
<p style="padding-left: 5px;">
To test these hypotheses, we conducted three experiments. Participants
were presented with fake Facebook posts containing misinformation
targeting specific ethnic groups and were sorted into different
conditions, including no misinformation post and no comments,
misinformation post and no replies, misinformation post with in-group
correction, and misinformation post with out-group correction. Before
and after the treatment (misinformation post), participants were asked
their belief in specific misinformation. The experiments relied on two
survey waves that oversampled black (both surveys) and Latino (first
survey only) respondents. Both experiments were sponsored by the
Weidenbaum Center at Washington University in Saint Louis and
distributed by NORC.
</p>
<ul>
<div class="image-container2" id="imageContainer2">
<img src='images/misinfo3.png' class="image-zoom2" id="imageZoom2">
<div>
</ul>
<hr />
<h3 style="color:Black;font-size:18px;">
Methods
</h3>
<p style="padding-left: 5px;">
In this project, I used the programming language R and used several
packages (readr, dplyr, magrittr, knitr, ggplot2, labelled, haven,
tidyverse, OneR, texreg, and weights) to perform data analysis. To
analyze the data, I used techniques such as weighted means, confidence
intervals, and linear regression. After manipulating the data to create
new variables, I used regression models to examine the impact of
treatments (or lack thereof) on different racial and ethnic groups’
susceptibility to misinformation. I also created tables that displayed
estimates, standard errors, and confidence intervals for different
treatments and racial/ethnic groups.
</p>
</div>
<button class="collapsible">
<p2>IMPLEMENTING LARGE SCALE SURVEY EXPERIMENTS </p2>
<mark style="color:#B8C0AF;font-size:11px;background:#f7f7f7"> [RESEARCH
DESIGN; SURVEY CREATION &amp; IMPLEMENTATION; PUBLICATION] </mark>
</button>
<div class="content">
<p>
<ul>
<h2 style="color:Black;font-size:18px;">
Main Contributions
</h2>
<ul>
<li>
Formulated a compelling hypothesis on motivated reasoning and logical
argument evaluation in political science
</li>
<li>
Designed 2 large-n survey experiments generating a robust and insightful
data set
</li>
<li>
Secured ethics approval, upholding the highest research standards
</li>
<li>
Conducted advanced data analysis with R packages, revealing key insights
on argument evaluation and objectivity interventions
</li>
<hr />
</ul>
</p>
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
<p>This data science project investigated the influence of motivated
reasoning on individuals’ evaluation of logical arguments, addressing
three key questions:</p>
<p style="padding-left: 10px;">
<ol style="list-style-type: decimal">
<li>Can individuals distinguish between strong (logically consistent)
and weak (logically flawed) arguments?</li>
<li>Are evaluations of argument quality biased by individuals’
pre-existing beliefs?</li>
<li>Can biases in argument evaluation be mitigated by priming the
competing goal of objectivity?
</p></li>
</ol>
<p style="padding-left: 5px;">
Utilizing R and I designed and conducted two large-n survey experiments,
finding that individuals can distinguish between strong and weak
arguments, but exhibit a bias favoring statements aligned with their
preferences. This bias persisted across strong and weak arguments,
political and non-political topics, and multiple issue areas.
</p>
<div class="responsive-iframe-container">
<iframe src="images/typ.pdf" frameborder="0" allowfullscreen>
<blockquote>
</iframe>
</div>
</blockquote>
<p style="padding-left: 5px;">
The project also evaluated the effectiveness of priming objectivity
goals in reducing biases in argument evaluation. The first study
suggested potential improvements in weak argument evaluation accuracy,
while the second study showed no measurable effect.
</p>
<p style="padding-left: 5px;">
<p>This research revealed the pervasiveness of argument congruency bias
and demonstrated that individuals’ biases influence, but do not entirely
overwhelm, their ability to accurately rate argument quality. By
exploring the potential of priming objectivity as an intervention, this
project contributed valuable insights into argument evaluation and
strategies for reducing.</p>
</p>
</div>
<button class="collapsible">
<p2>INTRODUCTION TO PYTHON FOR PUBLIC HEALTH MASTERS’ </p2>
<mark style="color:#B8C0AF;font-size:11px;background:#f7f7f7">
[INSTRUCTION; MACHINE LEARNING; NLP; OOP; DATA VISUALIZATION] </mark>
</button>
<div class="content">
<p>
<ul>
<h2 style="color:Black;font-size:16px;">
Main Contributions
</h2>
<ul >
<li>
Designed and implemented a beginner-friendly curriculum, tailored for
students with no prior programming experience.
</li>
<li>
Fostered an engaging and collaborative learning atmosphere by utilizing
GitHub Classroom, Jupyter Lab, and the univeristy’s LMS.
</li>
<hr />
<div class="responsive-iframe-container">
<iframe src="https://domlockett.github.io/website/Lecture1.3_Activity0-0.slides.html#/
" frameborder="0" allowfullscreen>
<blockquote>
</iframe>
</div>
</blockquote>
<li>
Facilitated student comprehension by providing real-world examples with
publicly available data.
</li>
<li>
Conducted in-class lectures, live coding sessions, and hands-on
programming exercises to facilitate student learning
</li>
<li>
Provided personalized feedback and support to students to enhance their
comprehension and performance
</li>
<li>
Developed and administered quizzes and assignments to evaluate student
progress and adjust teaching strategies
</li>
<div class="responsive-iframe-container">
<iframe src="https://nbviewer.org/github/domlockett91/github.io/blob/master/Final-Assignment.ipynb" frameborder="0" allowfullscreen>
<blockquote>
</iframe>
</div>
</ul>
</blockquote>
</ul>
</p>
</div>
</ul>
</p>
</div>
<button class="collapsible">
Methods coursework
</button>
<div class="content">
<p>
<ul>
<li>
<strong>Quantitative political methodology II</strong>
<mark style="color:#B8C0AF;background:#f7f7f7;">
(2023)</mark></strong><br>
<p style="padding-left: 20px;">
Taught by Jacob Montgomery (advisor). Primary materials: <i> Linear
Models with R</i> (Julian Faraway). Required.<br> This is a second
course in political methodology covering advanced methods of statistical
analysis for political and other social scientists. Covers maximum
likelihood estimation for various cross-sectional, time series, and
measurement models.
</li>
<div class="iframe-container">
<iframe src="methods.pdf" frameborder="0" width="40%" height="40%">
</iframe>
</div>
<li>
<strong>Computational social science</strong>
<mark style="color:#B8C0AF;background:#f7f7f7;"> (2023)</mark><br>
<p style="padding-left: 20px;">
Taught by Christopher Lucas.<br> Primary materials: <i> Pattern
Recognition and Machine Learning</i> (Christopher Bishop);<i> A Course
in Machine Learning</i> (Hal Daumé); <i>The Elements of Statistical
Learning: Data Mining, Inference, and Prediction</i> (Jerome Friedman,
Trevor Hastie, Robert Tibshirani).<br> This coursed focused on exposing
us to different types of data; including networks; text; audio; images;
and videos. We began with a mechanistic approaches to supervised and
unsupervised learning, then moved to statistical inference with
probabilistic interpretations.
</li>
</p>
<li>
<strong>Maximum likelihood estimation</strong>
<mark style="color:#B8C0AF;background:#f7f7f7;"> (2023)</mark><br>
<p style="padding-left: 20px;">
Taught by Julia Park.<br> This course focused on generalized linear
model estimation. We had practical exposure to link functions for a
number of models including multinomial and unordered models; ordered
outcome models; duration models; count models etc.
</li>
<li>
<strong>Causal inference</strong>
<mark style="color:#B8C0AF;background:#f7f7f7;"> (2022)</mark><br>
<p style="padding-left: 20px;">
Taught by Julia Park.<br> This coursed aimed to introduce theoretical
frameworks for causality and the empirical tools used in the estimation
of causal effects. This class had us learn and apply skills related to
outcomes; causal graphs; experiments; matching; regression;
difference-in-differences; instrumental variables; sensitivity analysis;
regression discontinuity etc.
</li>
<li>
<strong>Applied statistical programming</strong>
<mark style="color:#B8C0AF;background:#f7f7f7;"> (2022)</mark><br>
<p style="padding-left: 20px;">
Taught by Jacob Montgomery (advisor). Primary materials: <i> R for
dummies</i> (de Vries and Meys); <i>Advanced R</i> (Hadley Wickham).<br>
This course aimed to build our skill in programming (R) and expose us to
the underpinnings of object-oriented programming. Focused on teaching
foundational meta-skills from computer science and statistics such as
structures; control/flow; functions; version control/documentation;
classes and methods; apply/parallel; debugging and creating packages.
</li>
<li>
<strong>Theories of Individual and Collective Choice
I</strong><mark style="color:#B8C0AF;background:#f7f7f7;">
(2022)</mark><br>
<p style="padding-left: 20px;">
Taught by Keith Schnakenberg. Primary materials: <i> Game Theory: An
Introduction</i> (Steven Tadelis). Required.<br> This class was in an
introduction to rational choice theory and exposed us to spatial theory
of electoral competition; cooperative game theory; and general
equilibrium theory.
</li>
<li>
<strong>Quantitative political methodology I</strong>
<mark style="color:#B8C0AF;background:#f7f7f7;"> (2022)</mark><br>
<p style="padding-left: 20px;">
Taught by Guillermo Rosas. Primary materials: <i> Linear Models with R
</i>(Julian Faraway). Required.<br> This course explored the
fundamentals of linear regression models in both scalar and matrix form.
Problem sets focused on estimation; inference; specification; diagnostic
tools; data management; statistical computation.
</li>
<li>
<strong>Mathematical modeling</strong>
<mark style="color:#B8C0AF;background:#f7f7f7;">
(2021)</mark></mark><br>
<p style="padding-left: 20px;">
Taught by Randy Calvert. Primary materials: <i>Mathematics for
Economists</i> (Pemberton and Rau). Required.<br> This course covered
single-variable calculus and portions of multi-variate calculus, linear
algebra, and probability theory exposing us to topics including sets and
relations; probability; differential calculus and optimization;
difference equations; and linear algebra.
</li>
</p>
<li>
<strong>Research design</strong>
<mark style="color:#B8C0AF;background:#f7f7f7;"> (2021)</mark><br>
<p style="padding-left: 20px;">
Taught by Matt Gabel. Primary materials: <i> Political Science and the
Logic of Representations</i> (Kevin A. Clarke, David M. Primo); <i>The
logic of real arguments</i> (Alec Fisher). Required.<br> This course
focused on the philosophy of science and its implications for and
applications in political science research. The course had three parts:
examining the nature of scientific knowledge and scientific progress;
considering how scientific principles of defining, evaluating, and
developing knowledge can be applied to understanding political
phenomena; identifying standards for evaluation and making good social
scientific arguments and explanations.
</li>
</ul>
</p>
</div>
<button class="collapsible">
Résumé
</button>
<div class="content">
<p>
<ul>
<div class="responsive-iframe-container">
<iframe src="images/Lockett_resume23.pdf" frameborder="0" allowfullscreen>
</iframe>
</ul>
</p>
</div>
<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}

   function disableContextMenuInIframe() {
          const iframe = document.getElementById("my-iframe");
          iframe.contentWindow.document.addEventListener("contextmenu", (event) => {
              event.preventDefault();
          });
      }


</script>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
