<!DOCTYPE html>

<html>

<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta charset="utf-8" >
<meta name="generator" content="pandoc" >
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" >




<title>Portfolio</title>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
<script src="site_libs/header-attrs-2.19/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" >
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" >
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" >
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="stylesheet" href="styles.css" >
</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HOME</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Portfolio.html">Portfolio</a>
</li>
<li>
  <a href="Contact.html">Contact</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Portfolio</h1>

</div>


<hr >
<button class="collapsible">
Projects
</button>
<div class="content">
<p>
<ul>
<button class="collapsible">
<p2>USING TEXT DATA TO STUDY THE IMPACT OF NEWS SOURCE ON DISCOURSE
</p2><p3>[NLP; BIG DATA; ETL; TRANSFORMER MODELS; LLM]</p3>
</button>
<div class="content">
<p>
<ul>
<h2 style="color:Black;font-size:18px;">
Main Contributions
</h2>
<ul>
<li>
Extracted billions of tweets and replies from Twitter API using SQL,
Python, and web scraping techniques
</li>
<li>
Transformed, cleansed, and normalized with Python, Pandas, and regular
expressions
</li>
<li>
Optimized data collection and transformation tasks using parallel
processing, indexing, and caching
</li>
<li>
Automated the data collection process to streamline data management
processes for multiple collaborators
</li>
<li>
Ensured data reliability and pipeline stability by developing logging
and alerting mechanism to handle errors
</li>
</ul>
<hr >
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
The purpose of this project was to explore the ways discourse varies
dependent upon the news outlet reporting. To do so, we collected Tweets
shared by news organizations and their replies dating back to 2017. The
data collected yielded (soon to be published) insights into variations
such as sentiment and similarity. It also invited the use of techniques
such as topic modeling and interrupted times series analyses surrounding
the events of January 6, 2022. We sought to understand patterns related
to the emotional charge and sentiment of text and how this varied across
different news outlets and topics.
</p>
<hr >
<h3 style="color:Black;font-size:18px;">
Methods
</h3>
<p style="padding-left: 5px;">
My major contribution to this project was the development of a reliable
ETL pipeline that enabled non-methods researchers to easily load and
explore the data. To do so, I first created a a Python script to parse
and normalize the data. This involved pagination to fetch large volumes
of data and error handling to handle API rate limits and other potential
issues. The data retrieved included tweet-level information, media-level
information, and context annotations. Logging was implemented to track
the progress of the script and help diagnose issues that may arise
during the data collection process. The main function was to allow
multiple users to divide the work and run the script in parallel without
repetition.
</p>
<p style="padding-left: 5px;">
I then developed a program that allowed users to automatically extract
useful metrics from the data, store the cleansed data in a SQL database
and prevent duplicate data processing. This program included
preprocessing the text data with methods such as removing unnecessary
characters, renaming columns, extracting links, tokenization,
lemmatization and calculating various text-based metrics like average
word length and total word count. Other features include an unsupervised
learning algorithm for obtaining vector representations of words and
computing the subjectivity, polarity, and sentiment analysis scores for
each tweet
</p>
</ul>
</p>
</div>
<button class="collapsible">
    <p2>IDENTIFYING WHAT CONSTITUTES A POLITICAL ADVERTISEMENT</p2>
    <p3>[DATA ANALYSIS &amp; VISUALIZATION; CONJOINT EXPERIMENT]</p3>
</button>
<div class="content">
<ul>
<h2 style="color:Black;font-size:18px;">
Main Contributions
</h2>
<ul>
<li>
Collaborated with multidisciplinary team, providing insights and
recommendations based on key findings
</li>
<li>
Conducted exploratory data analysis using data visualization tools such
as ggplot2 and plotly
</li>
<li>
Identified experiment-breaking distribution error which necessitated
reissuance
</li>
<li>
Implemented data transformation techniques including variable recoding,
data aggregation, and normalization
</li>
<li>
Presented research findings in poster (displayed below) with
visualizations, summary and Q &amp; A at the Annual Conference for
Political Methodology
</li>
</ul>
<ul>
<div class="image-container" id="imageContainer">
<img src='images/poster.jpg' class="image-zoom" id="imageZoom">
<div>
</ul>
<hr >
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
In this project, we investigated social media users’ perceptions of
digital political ads. We measured users’ opinions on how platforms
should design political ad UX and policies with the goal of establishing
a baseline understanding of user opinions’ including the permissibility of
political ads and microtargeting, transparency in funding.
</p>
<p style="padding-left: 5px;">
The primary objective of this research was to understand what factors of
ads (and users themselves) may contribute to their perceptions of how
'political' given digital ads are. To do this, we conducted a conjoint
experiment asking respondents to compare artificial Facebook ads where
we altered their source, content, and political orientation. This
conjoint design allowed us to isolate the independent effects of each
component on perceptions of the political.
</p>
<p style="padding-left: 5px;">
We also conducted a within-between experiment asking respondents to
evaluate real ads drawn from the Facebook Ad Library (collected by
co-author). In this portion of the project, we randomly assigned
respondents to view either a political or non-political advertisement
and asked to rate how political they perceived it to be. Respondents
rated multiple ads (within-subject variation) but the exact composition
of the ads was randomized for each respondent (between-subject
variation).
</p>
<p style="padding-left: 5px;">
Overall, our conjoint analysis strongly supported our original research
hypotheses showing that the source, strength, and orientation of the
message all matter. We found that candidate ads seem to be viewed as
inherently political, in contrast to sources such as politically active
companies and advocacy organizations, where message strength appears to
matter far more in order for an ad to be considered political. This
differs from our finding in the conjoint analysis, where ads from
companies and advocacy organizations were viewed as equally political.
</p>
<hr >
<h3 style="color:Black;font-size:18px;">
Methods
</h3>
<p style="padding-left: 5px;">
<p>I was brought into this project after the research design and
implementation stages of the surveys had taken place and tasked with the
responsibility of maintaining and overseeing the data for a project. I
quickly acquired a working understanding of the mathematical principles
and methodologies behind conjoint experiments, a less-common analytical
approach in my field. Upon examination of the data and methods, I
identified discrepancies in the expected number of profiles,
subsequently informing my collaborators of the error which had
compromised the random assignment. Consequently, the survey distributor
rectified the parameters and redistributed the survey, ensuring the
project’s successful progression.</p>

<p>
I implemented analyses in this project in R, using libraries such as
dplyr, magrittr, and tidyverse to analyze political ad data and examine
the impact of ad orientation on political preferences. I developed an R
script to clean and process the data in order to create relevant
variables and handle missingness. I implemented advanced data
manipulation techniques and reshaped the datasets to make them more
manageable for further analysis.
</p>
<p>
I then conducted a comprehensive analysis on political advertisement
data, encompassing four novel datasets. Utilizing weighted confidence
intervals and an array of statistical techniques, I visualized the
findings through point-range plots, effectively conveying the political
nature of the ad content. Additionally, I carried out a follow-up study
to further investigate the perceived political content of various
advertisements, expanding the project’s scope and providing a more
in-depth understanding of the relationship between ad content and
political affiliation.
</p>

<button class="collapsible">Detailed Methods</button>
<div class="content">
<h3 style="color:Black;font-size:18px;">
Initial Analyses and Descriptive Statistics
</h3>
<p style="padding-left: 5px;">
The initial analysis involved several core datasets, including `CJ.csv`, `datc.csv`, `pooled.csv`, `correction.csv`, `data.csv`, `original.csv`, and `ra.csv`. The primary focus was to understand the distribution and characteristics of the data. Descriptive statistics and exploratory data analysis were performed using the `dplyr` and `ggplot2` libraries in R.
</p>
<p style="padding-left: 5px;">
For instance, summary statistics were computed to identify the central tendencies and dispersion of key variables. Visualization techniques, such as histograms and scatter plots, were employed to examine the data distributions and potential outliers. This initial step was crucial to ensure the quality and reliability of the data before proceeding with more complex analyses.
</p>

<h3 style="color:Black;font-size:18px;">
Data Cleaning and Transformations
</h3>
<p style="padding-left: 5px;">
Data cleaning involved handling missing values, correcting inconsistencies, and transforming variables to suitable formats for analysis. The script `rep_cleaning-data.R` was utilized to perform these tasks. Key transformations included:
</p>
<ul>
<li>**Variable Recoding**: Recoded categorical variables to ensure consistency and relevance for analysis. For example, political party affiliations were standardized across datasets.</li>
<li>**Data Aggregation**: Aggregated data at different levels, such as individual respondent level or ad level, to facilitate various types of analyses.</li>
<li>**Normalization**: Applied normalization techniques to scale numerical variables, ensuring they were on a comparable scale.</li>
<li>**Missing Data Imputation**: Employed multiple imputation techniques to handle missing data, minimizing potential biases in the analysis.</li>
</ul>
<p style="padding-left: 5px;">
Additionally, advanced data manipulation techniques were applied using `tidyverse` functions to reshape the data, such as `spread` and `gather` functions for pivoting data frames, making them suitable for subsequent analyses.
</p>

<h3 style="color:Black;font-size:18px;">
Statistical Modeling and Visualization
</h3>
<p style="padding-left: 5px;">
The statistical analysis involved using regression models to understand the relationship between ad characteristics and political perceptions. The script `rep_main-models.R` was used to build and evaluate these models. Key steps included:
</p>
<ul>
<li>**Model Specification**: Defined the appropriate statistical models, including linear and logistic regression models, to analyze the data.</li>
<li>**Model Fitting**: Fitted the models to the data using the `lm` and `glm` functions in R, ensuring appropriate handling of predictor variables.</li>
<li>**Diagnostic Checks**: Conducted diagnostic checks to validate the assumptions of the models, including checking for multicollinearity, heteroscedasticity, and influential observations.</li>
</ul>
<p style="padding-left: 5px;">
Visualization of the results was performed using `ggplot2` and `plotly` libraries. The script `rep_main-plots.R` was employed to create detailed visualizations, such as point-range plots and interaction plots, to effectively communicate the findings.
</p>

</div>
</div>
<button class="collapsible">
<p2>IMPLEMENTING LARGE SCALE SURVEY EXPERIMENTS </p2> <p3> [RESEARCH
DESIGN; SURVEY CREATION &amp; IMPLEMENTATION; PUBLICATION] </p3>
</button>
<div class="content">
<p>
<ul>
<h2 style="color:Black;font-size:18px;">
Main Contributions
</h2>
<ul>
<li>
Formulated a compelling hypothesis on motivated reasoning and logical
argument evaluation in political science
</li>
<li>
Designed 2 large-n survey experiments generating a robust and insightful
data set
</li>
<li>
Secured ethics approval, upholding the highest research standards
</li>
<li>
Conducted advanced data analysis with R packages, revealing key insights
on argument evaluation and objectivity interventions
</li>
<hr >
</ul>
</p>
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
<p>This data science project investigated the influence of motivated
reasoning on individuals’ evaluation of logical arguments, addressing
three key questions:</p>
<p style="padding-left: 10px;">
<ol style="list-style-type: decimal">
<li>Can individuals distinguish between strong (logically consistent)
and weak (logically flawed) arguments?</li>
<li>Are evaluations of argument quality biased by individuals’
pre-existing beliefs?</li>
competing goal of objectivity?
</p></li>
</ol>
<p style="padding-left: 5px;">
Utilizing R and I designed and conducted two large-n survey experiments,
finding that individuals can distinguish between strong and weak
arguments, but exhibit a bias favoring statements aligned with their
preferences. This bias persisted across strong and weak arguments,
political and non-political topics, and multiple issue areas.
</p>

<div class="button-container">
<button id="exampleButton" class="collapsible">
Presentation Example
</button>  
<div class="content">
  <div class="pdf-container">
    <iframe  class="pdf-viewer" src="files/typ.pdf">
    </iframe>
  </div>
</div>
</div>


<p style="padding-left: 5px;">
The project also evaluated the effectiveness of priming objectivity
goals in reducing biases in argument evaluation. The first study
suggested potential improvements in weak argument evaluation accuracy,
while the second study showed no measurable effect.
</p>
<p style="padding-left: 5px;">
<p>This research revealed the pervasiveness of argument congruency bias
and demonstrated that individuals’ biases influence, but do not entirely
overwhelm, their ability to accurately rate argument quality. By
exploring the potential of priming objectivity as an intervention, this
project contributed valuable insights into argument evaluation and
strategies for reducing.</p>
</p>
</div>
<button class="collapsible">
<p2>INTRODUCTION TO PYTHON FOR PUBLIC HEALTH MASTERS’ </p2> <p3>
[INSTRUCTION; MACHINE LEARNING; NLP; OOP; DATA VISUALIZATION] </p3>
</button>
<div class="content">
<p>
<ul>
<h2 style="color:Black;font-size:16px;">
Main Contributions
</h2>
<ul >
<li>
Designed and implemented a beginner-friendly curriculum, tailored for
students with no prior programming experience.
</li>
<li>
Fostered an engaging and collaborative learning atmosphere by utilizing
GitHub Classroom, Jupyter Lab, and the univeristy’s LMS.
</li>
<hr>

<div class="button-container">
<button id="exampleButton" class="collapsible">
Introductory Slides Example
</button>  
<div class="content">
  <div class="pdf-container">
    <iframe  class="pdf-viewer" src="files/Lecture1.3_Activity0-0.slides.html">
    </iframe>
  </div>
</div>
</div>

<li>
Facilitated student comprehension by providing real-world examples with
publicly available data.
</li>
<li>
Conducted in-class lectures, live coding sessions, and hands-on
programming exercises to facilitate student learning
</li>
<li>
Provided personalized feedback and support to students to enhance their
comprehension and performance
</li>
<li>
Developed and administered quizzes and assignments to evaluate student
progress and adjust teaching strategies
</li>

<div class="button-container">
<button id="exampleButton" class="collapsible">
Python Exam Example
</button>  
<div class="content">
  <div class="pdf-container">
    <iframe  class="pdf-viewer" src="https://nbviewer.org/github/domlockett91/github.io/blob/master/files/Final-Assignment.ipynb">
    </iframe>
  </div>
</div>
</div>

</ul>
</blockquote>
</ul>
</p>
</div>
</ul>
</p>
</div>
<button class="collapsible">
Methods coursework
</button>

<div class="content">
<ul>
<li>
<strong>Quantitative political methodology II (2020)</strong><br>
<ul>
    <li>Advanced course focused on sophisticated statistical analysis methods for computational scientists.</li>
    <li>Emphasized maximum likelihood estimation for various scenarios, including cross-sectional, time series, and non-parametric bootstrapping.</li>
    <li>Materials: <i>All of Statistics: A Concise Course in Statistical Inference</i>, Larry Wasserman; <i>R Programming for Data Science</i>, Roger D. Peng; <i>R for Data Science</i>, Garrett Grolemund and Hadley Wickham; <i>Statistical Inference (2nd Edition)</i>, George Casella and Roger L. Berger; <i>Bayesian Data Analysis (Third Edition)</i>, Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin.; Taught by Jacob Montgomery.</li>
</ul>
</li>

<div class="button-container">
<button id="exampleButton" class="collapsible">
Presentation Example
</button>  
<div class="content">
  <div class="pdf-container">
    <iframe class="pdf-viewer" src="files/methods.pdf">
    </iframe>
  </div>
</div>
</div>

<li>
<strong>Computational social science (2020)</strong><br>
<ul>
    <li>Explored various data types in social science, including networks, text, audio, images, and videos.</li>
    <li>Focused on both mechanistic and probabilistic approaches to supervised and unsupervised learning.</li>
    <li>Materials: <i>Pattern Recognition and Machine Learning</i>, Christopher Bishop; <i>A Course in Machine Learning</i>, Hal Daumé; <i>The Elements of Statistical Learning</i>, Jerome Friedman, Trevor Hastie, Robert Tibshirani; Taught by Christopher Lucas.</li>
</ul>
</li>

<li>
<strong>Maximum likelihood estimation (2019)</strong><br>
<ul>
    <li>In-depth focus on MLE principles, including probability theory, likelihood functions, and properties of estimators like consistency and efficiency.</li>
    <li>Comprehensive study of generalized linear models using MLE, covering exponential family distributions, link functions, logistic and Poisson regression.</li>
    <li>Advanced MLE topics: handling categorical data, overdispersion in count data, model selection criteria (AIC, BIC), model fit assessment and diagnostics.</li>
    <li>Materials: <i>Generalized Linear Models</i>, Peter KDunn, Gordon KSmyth; Taught by Christopher Lucas.</li>
</ul>
</li>

<li>
<strong>Causal inference (2019)</strong><br>
<ul>
    <li>Deep exploration of causal inference theories, focusing on counterfactual reasoning, potential outcomes, and causal diagrams.</li>
    <li>Study of experimental design principles, including randomized trials, natural and field experiments.</li>
    <li>Exploration of observational techniques: propensity score matching, regression discontinuity, difference-in-differences, instrumental variables.</li>
    <li>Advanced statistical methods for causal estimation: structural equation modeling, mediation analysis, sensitivity analysis</li>
    <li>Taught by Julia Park.</li>
</ul>
</li>

<li>
<strong>Applied statistical programming (2018)</strong><br>
<ul>
    <li>Introduced object-oriented programming, functional programming paradigms, and efficient data manipulation.</li>
    <li>Covered topics such as debugging, profiling, as well as package development and contribution to open-source projects.</li>
    <li>Emphasized statistical meta-skills like data cleaning, transformation, visualization, and implementation of various statistical models and algorithms.</li>
    <li>Materials: <i>R for Dummies</i>, de Vries and Meys; <i>Advanced R</i>, Hadley Wickham; Taught by Jacob Montgomery.</li>
</ul>
</li>

<li>
<strong>Theories of Individual and Collective Choice I (2018)</strong><br>
<ul>
    <li>Study of rational choice theory, delving into strategic decision-making processes, utility maximization, and behavioral strategy.</li>
    <li>Game-theoretic models: extensive and normal form games, Nash equilibrium concepts, repeated and dynamic games.</li>
    <li>Analysis of cooperative game theory, focusing on coalition formation, bargaining theories, and the Shapley value.</li>
    <li>Advanced topics: evolutionary game theory, Bayesian games, and information asymmetry in strategic interactions.</li>
    <li>Materials: <i>Game Theory: An Introduction</i>, Steven Tadelis; Taught by Keith Schnakenberg.</li>
</ul>
</li>

<li>
<strong>Quantitative political methodology I (2017)</strong><br>
<ul>
    <li>Explored mathematical underpinnings of linear regression models, exploring both scalar and matrix representations.</li>
    <li>Covered extensive topics including estimation techniques, inference methods, assumptions of linear models, diagnostic procedures, and the implementation of these concepts in statistical computation.</

li>
    <li>Special focus on understanding the Gauss-Markov theorem, least squares estimation, multicollinearity, heteroskedasticity, and model specification errors.</li>
    <li>Materials: <i>Linear Models with R</i>, Julian Faraway; Taught by Guillermo Rosas.</li>
</ul>
</li>

<li>
<strong>Mathematical modeling (2017)</strong><br>
<ul>
    <li>Explore advanced mathematical concepts, particularly matrix algebra and calculus, within the framework of economic modeling.</li>
    <li>Topics include matrix operations, determinants, eigenvalues and eigenvectors, and their applications in solving linear systems.</li>
    <li>Covered single-variable and multivariate calculus, including a detailed study of limits, continuity, differentiation, and integration.</li>
    <li>Materials: <i>Mathematics for Economists</i>, Pemberton and Rau; Taught by Randy Calvert.</li>
</ul>
</li>

<li>
<strong>Research design (2017)</strong><br>
<ul>
    <li>Explored the application of the philosophy of science in the social sciences.</li>
    <li>Topics included research methodologies, hypothesis formation and testing, the structure of scientific inquiry, and the principles of logical reasoning.</li>
    <li>Addressed the challenges of causality, including the design of experiments and observational studies, and the use of statistical methods for causal inference.</li>
    <li>Materials: <i>Political Science and the Logic of Representations</i>, Kevin A Clarke and David M Primo; <i>The Logic of Real Arguments</i>, Alec Fisher; Taught by Matt Gabel.</li>
</ul>
</li>
</ul>
</div>

<button class="collapsible">
Résumé
</button>
<div class="content">
<div class="invisible-container custom-width1"></div> 
  <div class="pdf-container" >
  <iframe class="pdf-viewer" src="files/Lockett_Resume24.pdf" frameborder="0"></iframe>
  <div class="pdf-error">Error: Unable to display PDF.</div>
  <div class="pdf-spinner">
    <img src="path/to/spinner.gif" alt="Loading..." />
  </div>
    </div>
  </div>

<script src="js/script.js"></script>

</div>

</body>
</html>
