<!DOCTYPE html>

<html>

<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta charset="utf-8" >
<meta name="generator" content="pandoc" >
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" >




<title>Portfolio</title>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
<script src="site_libs/header-attrs-2.19/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" >
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" >
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" >
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="stylesheet" href="styles.css" >
</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HOME</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Portfolio.html">Portfolio</a>
</li>
<li>
  <a href="Contact.html">Contact</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Portfolio</h1>

</div>


<hr >
<button class="collapsible">
Projects
</button>
<div class="content">
<p>
<ul>
<button class="collapsible">
<p2>USING TEXT DATA TO STUDY THE IMPACT OF NEWS SOURCE ON DISCOURSE
</p2><p3>[NLP; BIG DATA; ETL; TRANSFORMER MODELS; LLM]</p3>
</button>
<div class="content">
<p>
<ul>
<h2 style="color:Black;font-size:18px;">
Main Contributions
</h2>
<ul>
<li>
Extracted billions of tweets and replies from Twitter API using SQL,
Python, and web scraping techniques
</li>
<li>
Transformed, cleansed, and normalized with Python, Pandas, and regular
expressions
</li>
<li>
Optimized data collection and transformation tasks using parallel
processing, indexing, and caching
</li>
<li>
Automated the data collection process to streamline data management
processes for multiple collaborators
</li>
<li>
Ensured data reliability and pipeline stability by developing logging
and alerting mechanism to handle errors
</li>
</ul>
<hr >
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
The purpose of this project was to explore the ways discourse varies
dependent upon the news outlet reporting. To do so, we collected Tweets
shared by news organizations and their replies dating back to 2017. The
data collected yielded (soon to be published) insights into variations
such as sentiment and similarity. It also invited the use of techniques
such as topic modeling and interrupted times series analyses surrounding
the events of January 6, 2022. We sought to understand patterns related
to the emotional charge and sentiment of text and how this varied across
different news outlets and topics.
</p>
<hr >
<h3 style="color:Black;font-size:18px;">
Methods
</h3>
<p style="padding-left: 5px;">
My major contribution to this project was the development of a reliable
ETL pipeline that enabled non-methods researchers to easily load and
explore the data. To do so, I first created a a Python script to parse
and normalize the data. This involved pagination to fetch large volumes
of data and error handling to handle API rate limits and other potential
issues. The data retrieved included tweet-level information, media-level
information, and context annotations. Logging was implemented to track
the progress of the script and help diagnose issues that may arise
during the data collection process. The main function was to allow
multiple users to divide the work and run the script in parallel without
repetition.
</p>
<p style="padding-left: 5px;">
I then developed a program that allowed users to automatically extract
useful metrics from the data, store the cleansed data in a SQL database
and prevent duplicate data processing. This program included
preprocessing the text data with methods such as removing unnecessary
characters, renaming columns, extracting links, tokenization,
lemmatization and calculating various text-based metrics like average
word length and total word count. Other features include an unsupervised
learning algorithm for obtaining vector representations of words and
computing the subjectivity, polarity, and sentiment analysis scores for
each tweet
</p>
</ul>
</p>
</div>
<button class="collapsible">
<p2>IDENTIFYING WHAT CONSTITUTES A POLITICAL ADVERTISEMENT </p2> <p3>
[DATA ANALYSIS &amp; VISUALIZTION; CONJOINT EXPERIMENT]</p3>
</button>
<div class="content">
<ul>
<h2 style="color:Black;font-size:18px;">
Main Contributions
</h2>
<ul>
<li>
Collaborated with multidisciplinary team, providing insights and
recommendations based on key findings
</li>
<li>
Conducted exploratory data analysis using data visualization tools such
as ggplot2 and plotly
</li>
<li>
Identified experiment-breaking distribution error which necessitated
reissuance
</li>
<li>
Implemented data transformation techniques including variable recoding,
data aggregation, and normalization
</li>
<li>
Presented research findings in poster (displayed below) with
visualizations, summary and Q &amp; A at the Annual Conference for
Political Methodology
</li>
</ul>
<ul>
<div class="image-container" id="imageContainer">
<img src='images/poster.jpg' class="image-zoom" id="imageZoom">
<div>
</ul>
<hr >
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
In this project, we investigated social media users’ perceptions of
digital political ads. We measured users’ opinions on how platforms
should design political ad UX and policies with the goal of establishing
a baseline understanding of user opinions’ including the permissibly of
political ads and microtargeting, transparency in funding.
</p>
<p style="padding-left: 5px;">
The primary objective of this research was to understand what factors of
ads (and users themselves) may contribute to their perceptions of how
`political’ given digital ads are. To do this, we conducted a conjoint
experiment asking respondents to compare artificial Facebook ads where
we altered their source, content, and political orientation. This
conjoint design allowed us to isolate the independent effects of each
component on perceptions of the political.
</p>
<p style="padding-left: 5px;">
We also conducted a within-between experiment asking respondents to
evaluate real ads drawn from the Facebook Ad Library (collected by
co-author). In this portion of the project, we randomly assigned
respondents’ to view either a political or non-political advertisement
and asked to rate how political they perceived it to be. Respondents
rated multiple ads (within-subject variation) but the exact composition
of the ads was randomized for each respondent (between-subject
variation)
</p>
<p style="padding-left: 5px;">
Overall, our conjoint analysis strongly supported our original research
hypotheses showing that the source, strength, and orientation of the
message all matter. We found that candidate ads seem to be viewed as
inherently political, in contrast to sources such as politically active
companies and advocacy organizations, where message strength appears to
matter far more in order for an ad to be considered political. This
differs from our finding in the conjoint analysis, where ads from
companies and advocacy organizations were viewed as equally political.
</p>
<hr >
<h3 style="color:Black;font-size:18px;">
Methods
</h3>
<p style="padding-left: 5px;">
<p>I was brought into this project after the research design and
implementation stages of the surveys had taken place and tasked with the
responsibility of maintaining and overseeing the data for a project. I
quickly acquired a working understanding of the mathematical principles
and methodologies behind conjoint experiments, a less-common analytical
approach in my field. Upon examination of the data and methods, I
identified discrepancies in the expected number of profiles,
subsequently informing my collaborators of the error which had
compromised the random assignment. Consequently, the survey distributor
rectified the parameters and redistributed the survey, ensuring the
project’s successful progression.</p>

<p>
I implemented analyses in this project in R, using libraries such as
dplyr, magrittr, and tidyverse to analyze political ad data and examine
the impact of ad orientation on political preferences. I developed an R
script to clean and process the data in order to create relevant
variables and handle missingness. I implemented advanced data
manipulation techniques and reshaped the datasets to make them more
manageable for further analysis.
</p>
<p>
I then conducted a comprehensive analysis on political advertisement
data, encompassing four novel datasets. Utilizing weighted confidence
intervals and an array of statistical techniques, I visualized the
findings through point-range plots, effectively conveying the political
nature of the ad content. Additionally, I carried out a follow-up study
to further investigate the perceived political content of various
advertisements, expanding the project’s scope and providing a more
in-depth understanding of the relationship between ad content and
political affiliation.
</p>
<p>
Across the two experiments, we found no evidence supporting our
hypotheses. While Study 1 showed that corrective comments in the
comments section effectively reduced misperceptions, culturally relevant
corrections were not particularly effective among Latinos. In Study 2,
we did not find evidence to support the hypothesis that culturally
relevant comments are more effective in reducing misperceptions.
Interestingly, the in-group corrections from those who were the target
of misinformation were most effective among all participants in both
experiments, which may suggest that members of out-groups defer to other
ethnic groups when the misinformation does not relate to them.
</p>
</div>
<button class="collapsible">
<p2>MEASURING THE EFFICACY OF IN-GROUP CORRECTIONS</p2>
<p3>[EXPERIMENTAL DESIGN; DATA ANALYSIS &amp; VISUALIZATION]</p3>
</button>
<div class="content">
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
This project aimed to investigate the effectiveness of corrective
comments on social media in reducing misinformation, specifically
examining the role of in-group and out-group members in promoting
accurate beliefs. We hypothesized that comments from in-group members
would be more effective in promoting accurate beliefs than comments from
out-group members, particularly when the misinformation relates to the
target’s ethnic group. We also hypothesized that corrective comments
from culturally relevant organizations would be more effective in
reducing misperceptions.
</p>
<ul>
<div class="image-container" id="imageContainer">
<img src='images/misinfo.png' class="image-zoom" id="imageZoom">
<div>
</ul>
<p style="padding-left: 5px;">
To test these hypotheses, we conducted three experiments. Participants
were presented with fake Facebook posts containing misinformation
targeting specific ethnic groups and were sorted into different
conditions, including no misinformation post and no comments,
misinformation post and no replies, misinformation post with in-group
correction, and misinformation post with out-group correction. Before
and after the treatment (misinformation post), participants were asked
their belief in specific misinformation. The experiments relied on two
survey waves that oversampled black (both surveys) and Latino (first
survey only) respondents. Both experiments were sponsored by the
Weidenbaum Center at Washington University in Saint Louis and
distributed by NORC.
</p>
<ul>
<div class="image-container2" id="imageContainer2">
<img src='images/misinfo3.png' class="image-zoom2" id="imageZoom2">
<div>
</ul>
<hr >
<h3 style="color:Black;font-size:18px;">
Methods
</h3>
<p style="padding-left: 5px;">
In this project, I used the programming language R and used several
packages (readr, dplyr, magrittr, knitr, ggplot2, labelled, haven,
tidyverse, OneR, texreg, and weights) to perform data analysis. To
analyze the data, I used techniques such as weighted means, confidence
intervals, and linear regression. After manipulating the data to create
new variables, I used regression models to examine the impact of
treatments (or lack thereof) on different racial and ethnic groups’
susceptibility to misinformation. I also created tables that displayed
estimates, standard errors, and confidence intervals for different
treatments and racial/ethnic groups.
</p>
</div>
<button class="collapsible">
<p2>IMPLEMENTING LARGE SCALE SURVEY EXPERIMENTS </p2> <p3> [RESEARCH
DESIGN; SURVEY CREATION &amp; IMPLEMENTATION; PUBLICATION] </p3>
</button>
<div class="content">
<p>
<ul>
<h2 style="color:Black;font-size:18px;">
Main Contributions
</h2>
<ul>
<li>
Formulated a compelling hypothesis on motivated reasoning and logical
argument evaluation in political science
</li>
<li>
Designed 2 large-n survey experiments generating a robust and insightful
data set
</li>
<li>
Secured ethics approval, upholding the highest research standards
</li>
<li>
Conducted advanced data analysis with R packages, revealing key insights
on argument evaluation and objectivity interventions
</li>
<hr >
</ul>
</p>
<h3 style="color:Black;font-size:18px;">
Summary
</h3>
<p style="padding-left: 5px;">
<p>This data science project investigated the influence of motivated
reasoning on individuals’ evaluation of logical arguments, addressing
three key questions:</p>
<p style="padding-left: 10px;">
<ol style="list-style-type: decimal">
<li>Can individuals distinguish between strong (logically consistent)
and weak (logically flawed) arguments?</li>
<li>Are evaluations of argument quality biased by individuals’
pre-existing beliefs?</li>
competing goal of objectivity?
</p></li>
</ol>
<p style="padding-left: 5px;">
Utilizing R and I designed and conducted two large-n survey experiments,
finding that individuals can distinguish between strong and weak
arguments, but exhibit a bias favoring statements aligned with their
preferences. This bias persisted across strong and weak arguments,
political and non-political topics, and multiple issue areas.
</p>

<div class="button-container">
<button id="exampleButton" class="collapsible">
Presentation Example
</button>  
<div class="content">
  <div class="pdf-container">
    <iframe  class="pdf-viewer" src="files/typ.pdf">
    </iframe>
  </div>
</div>
</div>


<p style="padding-left: 5px;">
The project also evaluated the effectiveness of priming objectivity
goals in reducing biases in argument evaluation. The first study
suggested potential improvements in weak argument evaluation accuracy,
while the second study showed no measurable effect.
</p>
<p style="padding-left: 5px;">
<p>This research revealed the pervasiveness of argument congruency bias
and demonstrated that individuals’ biases influence, but do not entirely
overwhelm, their ability to accurately rate argument quality. By
exploring the potential of priming objectivity as an intervention, this
project contributed valuable insights into argument evaluation and
strategies for reducing.</p>
</p>
</div>
<button class="collapsible">
<p2>INTRODUCTION TO PYTHON FOR PUBLIC HEALTH MASTERS’ </p2> <p3>
[INSTRUCTION; MACHINE LEARNING; NLP; OOP; DATA VISUALIZATION] </p3>
</button>
<div class="content">
<p>
<ul>
<h2 style="color:Black;font-size:16px;">
Main Contributions
</h2>
<ul >
<li>
Designed and implemented a beginner-friendly curriculum, tailored for
students with no prior programming experience.
</li>
<li>
Fostered an engaging and collaborative learning atmosphere by utilizing
GitHub Classroom, Jupyter Lab, and the univeristy’s LMS.
</li>
<hr>

<div class="button-container">
<button id="exampleButton" class="collapsible">
Introductory Slides Example
</button>  
<div class="content">
  <div class="pdf-container">
    <iframe  class="pdf-viewer" src="files/Lecture1.3_Activity0-0.slides.html">
    </iframe>
  </div>
</div>
</div>

<li>
Facilitated student comprehension by providing real-world examples with
publicly available data.
</li>
<li>
Conducted in-class lectures, live coding sessions, and hands-on
programming exercises to facilitate student learning
</li>
<li>
Provided personalized feedback and support to students to enhance their
comprehension and performance
</li>
<li>
Developed and administered quizzes and assignments to evaluate student
progress and adjust teaching strategies
</li>

<div class="button-container">
<button id="exampleButton" class="collapsible">
Python Exam Example
</button>  
<div class="content">
  <div class="pdf-container">
    <iframe  class="pdf-viewer" src="https://nbviewer.org/github/domlockett91/github.io/blob/master/files/Final-Assignment.ipynb">
    </iframe>
  </div>
</div>
</div>

</ul>
</blockquote>
</ul>
</p>
</div>
</ul>
</p>
</div>
<button class="collapsible">
Methods coursework
</button>
Sure, I'll help you modify the content under each course on your website (A) to match the bulleted format provided in version B. Here's the revised content:

---

<div class="content">
<ul>
<li>
<strong>Quantitative political methodology II (2020)</strong><br>
<ul>
    <li>Advanced course focused on sophisticated statistical analysis methods for computational scientists.</li>
    <li>Emphasized maximum likelihood estimation for various scenarios, including cross-sectional, time series, and non-parametric bootstrapping.</li>
    <li>Materials: <i>Linear Models with R</i>, Julian Faraway; Taught by Jacob Montgomery.</li>
</ul>
</li>

<div class="button-container">
<button id="exampleButton" class="collapsible">
Presentation Example
</button>  
<div class="content">
  <div class="pdf-container">
    <iframe class="pdf-viewer" src="files/methods.pdf">
    </iframe>
  </div>
</div>
</div>

<li>
<strong>Computational social science (2020)</strong><br>
<ul>
    <li>Explored various data types in social science, including networks, text, audio, images, and videos.</li>
    <li>Focused on both mechanistic and probabilistic approaches to supervised and unsupervised learning.</li>
    <li>Materials: <i>Pattern Recognition and Machine Learning</i>, Christopher Bishop; <i>A Course in Machine Learning</i>, Hal Daumé; <i>The Elements of Statistical Learning</i>, Jerome Friedman, Trevor Hastie, Robert Tibshirani; Taught by Christopher Lucas.</li>
</ul>
</li>

<li>
<strong>Maximum likelihood estimation (2019)</strong><br>
<ul>
    <li>In-depth focus on MLE principles, including probability theory, likelihood functions, and properties of estimators like consistency and efficiency.</li>
    <li>Comprehensive study of generalized linear models using MLE, covering exponential family distributions, link functions, logistic and Poisson regression.</li>
    <li>Advanced MLE topics: handling categorical data, overdispersion in count data, model selection criteria (AIC, BIC), model fit assessment and diagnostics.</li>
    <li>Materials: <i>Generalized Linear Models</i>, Peter KDunn, Gordon KSmyth; Taught by Christopher Lucas.</li>
</ul>
</li>

<li>
<strong>Causal inference (2019)</strong><br>
<ul>
    <li>Deep exploration of causal inference theories, focusing on counterfactual reasoning, potential outcomes, and causal diagrams.</li>
    <li>Study of experimental design principles, including randomized trials, natural and field experiments.</li>
    <li>Exploration of observational techniques: propensity score matching, regression discontinuity, difference-in-differences, instrumental variables.</li>
    <li>Advanced statistical methods for causal estimation: structural equation modeling, mediation analysis, sensitivity analysis; Taught by Julia Park.</li>
</ul>
</li>

<li>
<strong>Applied statistical programming (2018)</strong><br>
<ul>
    <li>Introduced object-oriented programming, functional programming paradigms, and efficient data manipulation.</li>
    <li>Covered topics such as debugging, profiling, as well as package development and contribution to open-source projects.</li>
    <li>Emphasized statistical meta-skills like data cleaning, transformation, visualization, and implementation of various statistical models and algorithms.</li>
    <li>Materials: <i>R for Dummies</i>, de Vries and Meys; <i>Advanced R</i>, Hadley Wickham; Taught by Jacob Montgomery.</li>
</ul>
</li>

<li>
<strong>Theories of Individual and Collective Choice I (2018)</strong><br>
<ul>
    <li>Study of rational choice theory, delving into strategic decision-making processes, utility maximization, and behavioral strategy.</li>
    <li>Game-theoretic models: extensive and normal form games, Nash equilibrium concepts, repeated and dynamic games.</li>
    <li>Analysis of cooperative game theory, focusing on coalition formation, bargaining theories, and the Shapley value.</li>
    <li>Advanced topics: evolutionary game theory, Bayesian games, and information asymmetry in strategic interactions.</li>
    <li>Materials: <i>Game Theory: An Introduction</i>, Steven Tadelis; Taught by Keith Schnakenberg.</li>
</ul>
</li>

<li>
<strong>Quantitative political methodology I (2017)</strong><br>
<ul>
    <li>Explored mathematical underpinnings of linear regression models, exploring both scalar and matrix representations.</li>
    <li>Covered extensive topics including estimation techniques, inference methods, assumptions of linear models, diagnostic procedures, and the implementation of these concepts in statistical computation.</

li>
    <li>Special focus on understanding the Gauss-Markov theorem, least squares estimation, multicollinearity, heteroskedasticity, and model specification errors.</li>
    <li>Materials: <i>Linear Models with R</i>, Julian Faraway; Taught by Guillermo Rosas.</li>
</ul>
</li>

<li>
<strong>Mathematical modeling (2017)</strong><br>
<ul>
    <li>Explore advanced mathematical concepts, particularly matrix algebra and calculus, within the framework of economic modeling.</li>
    <li>Topics include matrix operations, determinants, eigenvalues and eigenvectors, and their applications in solving linear systems.</li>
    <li>Covered single-variable and multivariate calculus, including a detailed study of limits, continuity, differentiation, and integration.</li>
    <li>Materials: <i>Mathematics for Economists</i>, Pemberton and Rau; Taught by Randy Calvert.</li>
</ul>
</li>

<li>
<strong>Research design (2021)</strong><br>
<ul>
    <li>Explored the application of the philosophy of science in the social sciences.</li>
    <li>Topics included research methodologies, hypothesis formation and testing, the structure of scientific inquiry, and the principles of logical reasoning.</li>
    <li>Addressed the challenges of causality, including the design of experiments and observational studies, and the use of statistical methods for causal inference.</li>
    <li>Materials: <i>Political Science and the Logic of Representations</i>, Kevin A Clarke and David M Primo; <i>The Logic of Real Arguments</i>, Alec Fisher; Taught by Matt Gabel.</li>
</ul>
</li>
</ul>
</div>

<button class="collapsible">
Résumé
</button>
<div class="content">
<div class="invisible-container custom-width1"></div> 
  <div class="pdf-container" >
  <iframe class="pdf-viewer" src="files/Lockett_resume23.pdf" frameborder="0"></iframe>
  <div class="pdf-error">Error: Unable to display PDF.</div>
  <div class="pdf-spinner">
    <img src="path/to/spinner.gif" alt="Loading..." />
  </div>
    </div>
  </div>

<script src="js/script.js"></script>

</div>

</body>
</html>
